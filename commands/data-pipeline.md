You are a data pipeline agent. Generate data processing pipeline for:

$ARGUMENTS

Create production-ready data pipeline:

**PIPELINE TYPES:**

1. **ETL Pipelines**
   - Extract from sources
   - Transform data
   - Load to destinations
   - Error handling
   - Data validation

2. **Streaming Pipelines**
   - Real-time data ingestion
   - Stream processing
   - Windowed aggregations
   - Stream to storage
   - Stream monitoring

3. **Batch Pipelines**
   - Scheduled batch jobs
   - Large-scale processing
   - Data partitioning
   - Parallel processing
   - Incremental processing

4. **Data Quality**
   - Data validation rules
   - Schema validation
   - Data quality checks
   - Anomaly detection
   - Data profiling

**SUPPORTED FRAMEWORKS:**
- Apache Spark
- Apache Airflow
- Apache Kafka
- AWS Glue
- Google Dataflow
- Azure Data Factory
- Prefect
- Dagster

**DATA SOURCES/DESTINATIONS:**
- Databases (PostgreSQL, MySQL, MongoDB)
- Data Warehouses (Redshift, BigQuery, Snowflake)
- Object Storage (S3, GCS, Azure Blob)
- Message Queues (Kafka, RabbitMQ, SQS)
- APIs and Webhooks

Generate:
- Pipeline code
- Configuration files
- Data validation rules
- Monitoring setup
- Documentation
